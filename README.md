# RAG-агент (ИИ-ассистент для студентов медицинских вузов)

![image](https://github.com/user-attachments/assets/87d11156-b2fa-477f-974e-2073d2adcc54)



# О проекте
-текст о работе в целом- 


# Устройство модели:

- Llama3.2 - главная LLM-модель, на которой построен агент
- intfloat/multilingual-e5-base _(for embeddings)_
- Tavily - сервис для выхода модели в WebSearch - получение API-ключа и выход в web
- Langchain - фреймворк для работы с LLM-моделями.
- LangGraph для описания текущих состояний модели - фреймворк для оркестровки агентных систем.


# Архитектура модели:
Агент обладает сложной структурой обработки текста и генерации.

Фактически он состоит из двух частей - одна отвечает за обработку PDF-файлов, добавляемых пользователем, после чего создает FAISS-индексы, чтобы хранить все данные в виде векторного хранилища.

Вторая часть отвечает за саму RAG-систему - сначала на вход подается запрос пользователя. Если он не связан с медициной, то включается WebSearch. Если он связан с медицинской тематикой, то запускается retriever на основе векторного хранилища, созданного первой частью модели. Далее ретривер старается найти 3 релевантных отрывка. Если он находит хотя бы 1 подходящий отрывок, то генерация запускается. Иначе снова отправляется в Websearch. Затем генерация проверяется на галлюцинации и совпадение вопроса с ответом. В случае, если что-то не так, модель самокорректируется - на это ей дано 3 попытки. 

Итого RAG обладает несколькими свойствами:
- Самокоррекция
- Маршрутизация
- Самооценка


![IMG_9517](https://github.com/user-attachments/assets/d508a5a2-ea56-468c-9bc0-a2ff18f948dd)


# Локальный запуск модели на своем железе

Для того, чтобы запустить агента, будет необходимо совершить несколько несложных действий. 

1. Скачать Ollama на ПК по ссылке - https://ollama.com/download/windows
_(windows 10+ версия)_
2. Открыть приложение Ollama и написать ```ollama pull llama3.2:3b-instruct-fp16``` в специальной командной строке. На этом этапе вы скачиваете llama3.2 на 3 миллиарда параметров.
3. На всякий случай проверить, скачалась ли модель - ```ollama list ```
4. Перед выполнением кода **обязательно** запускаем модель - ``` ollama run llama3.2``` - теперь модель готова работать!
5. Переходим к коду - открыть:
   
   1)  ``` main.py ```  - если хотите запустить модель без streamlit.
   2)  ``` main.py ``` + ``` Agent.py ``` + страницы из папки ```pages``` - если хотите запустить модель через streamlit
  
1) Использование модели без streamlit:
   
    (1.1)   Если хотите использовать _уже существующую_ базу знаний о медицине, то расскоментируйте последние 4 строчки кода и вставьте свой вопрос:
   
        ```  if __name__ == "__main__":
             inputs = {"question": "Что такое нейрон?", "max_retries": 3}
             for event in graph.stream(inputs, stream_mode="values"):
                logger.debug(event) ```
   
    (1.2)   Если хотите протестировать модель _на своей литературе_, то добавьте свой PDF-файл в папку ```/pdf/new``` . Затем вернитесь к пункту (1.1) и запишите свой вопрос. Запустите код. Ваш файл будет обработан как новый источник, и модель добавит его в векторное хранилище. Затем модель выдаст ответ.
 
2) Использование модели с streamlit:
    
     (2.1)   Откройте оба файла, пропишите в командной строке ``` streamlit run Agent.py ``` - перед вами откроется приложение. Если зададите вопрос в текстовой строке, то ответ будет сгенерирован на основе имеющейся базы знаний. Если загрузите в окошко слева свой PDF-файл, то он будет также добавлен в базу знаний. Далее модель выдает ответ пользователю.

   _Пример использования:_
   
   ![image](https://github.com/user-attachments/assets/a7d4cf9f-5059-4a2b-8086-a5ba7d0dfd57)

   _Пример использования модели на основе WebSearch:_
  
   ![image](https://github.com/user-attachments/assets/d4b07dc2-de01-4f36-a3dc-b4eb5504a546)


     (2.2)   Ради интереса можете посетить и другие страницы сайта - в них содержится информация о модели, статистика _(инфографика)_из опроса студентов медицинских вузов и общая информация о проекте.

# Другие элементы сайта
### About project:



![image](https://github.com/user-attachments/assets/2a093ecf-98c8-42a1-9ef8-297157842ea7)


### Statistics:



![image](https://github.com/user-attachments/assets/5e41186f-da0c-4d06-afbd-340e3671a9f7)


### About model:



![image](https://github.com/user-attachments/assets/15856f89-cc6e-4c94-be4f-961e7a757172)








